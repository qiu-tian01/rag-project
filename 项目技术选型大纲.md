# 项目技术选型（RAG：按“需求文档 → 需求点”追溯项目功能）

## 1. 背景与目标

### 1.1 业务问题
- **目标**：输入“项目功能/模块/用户故事/关键字”，快速定位**历史需求文档**中涉及该功能的**具体需求点**，并给出**可追溯证据**（文档名、版本、章节/段落、页码/标题、引用原文片段、相似度/置信度）。
- **典型输入**：功能名称、页面名、接口名、业务规则、异常场景、验收口径等。
- **典型输出**：
  - Top-K 需求点（含：文档ID/版本/发布日期/需求编号/标题/章节路径/原文摘录/引用定位/评分）
  - 可展开查看上下文（前后若干段）
  - “为什么命中”（关键词高亮、相似度、重写后的检索query）

### 1.2 核心能力清单（MVP → 可扩展）
- **文档接入**：
  - **飞书云文档**（主要来源）：通过飞书开放平台 API 同步文档内容，支持自动/手动同步、版本管理、增量更新。
  - **本地文件**（备选）：Word（`.docx`）、PDF、Markdown、HTML（可选：图片/扫描件 OCR）。
- **结构化切分**：按"章节标题→需求编号→条款"切分，保留层级路径。
- **可追溯引用**：返回答案必须附带引用（quote + 位置），支持跳转到飞书文档原始位置。
- **混合检索**：向量检索 + 关键词/全文检索 + 元数据过滤。
- **需求点识别**：从文档自动抽取"需求点/条款"并作为一等实体管理。
- **权限与审计**：按项目/文档范围授权；记录检索与访问审计。

## 2. 总体架构与数据流

### 2.1 架构概览（推荐）
- **前端**：Web 应用（查询、结果列表、引用预览、文档管理、权限管理）
- **后端 API**：RAG 服务（检索、重排、生成、引用拼装），文档入库与任务编排
- **数据存储**：
  - 业务关系数据（项目/文档/版本/需求点/权限/审计）
  - 向量索引（chunk/需求点向量）
  - 对象存储（原始文件、解析后的中间产物）
  - 缓存与队列（任务、会话、速率限制）
- **LLM/Embedding**：用于 query 改写、召回增强、重排（可选）、答案生成与引用整理

### 2.2 数据流（离线入库）

#### 方案 A：飞书云文档同步（推荐）
1) **文档注册**：管理员添加飞书文档 URL → 记录文档元数据（URL、标题、项目归属）  
2) **文档同步**：定时任务/手动触发 → 调用飞书 API 获取文档内容（Markdown/HTML/文本）  
3) **版本检测**：对比文档更新时间/内容 hash → 判断是否需要更新  
4) **解析**：提取文本/标题层级/表格 → 生成章节树  
5) **识别"需求点"**（规则 + LLM/NER，可选）  
6) **生成 chunk**（保留层级元数据）→ 7) **Embedding** → 8) 写入向量库 + 写入关系库（索引元数据）  
9) 可选：生成摘要、关键词、实体标签（功能、模块、接口、角色、系统名）

**增量更新策略**：
- 检测到文档变化 → 创建新版本 → 对比旧版本识别变化部分 → 只更新变化的 chunk（删除旧向量，插入新向量）

#### 方案 B：本地文件上传（备选）
1) 上传文档（Word/PDF）→ 2) 解析（提取文本/标题层级/页码/表格）  
3) 识别"需求点"（规则 + LLM/NER，可选）  
4) 生成 chunk（保留层级元数据）→ 5) Embedding → 6) 写入向量库 + 写入关系库（索引元数据）  
7) 可选：生成摘要、关键词、实体标签（功能、模块、接口、角色、系统名）

### 2.3 数据流（在线检索问答）
1) 用户 query → 2) query 改写/扩展（可选）  
3) 混合检索（向量 + BM25）+ 元数据过滤（项目/时间/版本/文档类型）  
4) 重排（Cross-Encoder 或 LLM 评分，可选）  
5) 生成答案（严格基于引用）+ 输出引用清单 + 可回溯定位信息

## 3. 技术选型总览（推荐组合 + 备选）

### 3.1 推荐默认方案（性价比/可控/企业落地友好）
- **前端**：Next.js（React + TypeScript）+ Tailwind CSS + Ant Design（或 shadcn/ui）
- **后端**：Python FastAPI（异步、高吞吐、生态成熟）
- **关系数据库**：PostgreSQL（承载业务数据与全文检索/结构化过滤）
- **向量能力**：PostgreSQL + FAISS/Milvus（混合架构：PostgreSQL 存元数据，FAISS/Milvus 做向量检索，通过 chunk_id 关联）
- **对象存储**：MinIO（测试环境，S3 兼容）+ 阿里云 OSS（生产环境，通过存储抽象层切换）
- **缓存/队列**：Redis + Celery（或 RQ/Arq）用于异步入库、重试、限流
- **RAG 框架**：LlamaIndex（文档索引、节点/元数据、检索链路清晰）  
  - 备选：LangChain（生态更广）、Haystack（检索工程化强）
- **重排模型**：Jina Reranker（云API，推荐）或 Cohere rerank（云API，备选）
- **Embedding**：Qwen embedding 模型（中文优化，推荐）
- **大模型（LLM）**：云泽云 API 的 Qwen 系列（推荐 Qwen-Max 或 Qwen-Plus，详见 8.3 节对比）

### 3.2 扩展方案（更大规模/更强检索）
- **向量数据库优化**：从 FAISS 升级到 Milvus（分布式、元数据过滤更强），或考虑 Qdrant / Weaviate（适合百万级以上向量与更复杂索引）
- **全文检索**：OpenSearch/Elasticsearch（BM25、聚合与权限过滤更强）
- **服务编排**：Kubernetes + Helm（多环境、弹性扩缩）

## 4. 前端选型

### 4.1 技术栈
- **框架**：Next.js（App Router）+ TypeScript
- **UI**：Tailwind CSS + Ant Design（表格/筛选/权限管理效率高）
- **状态与请求**：TanStack Query + Zustand（或 Redux Toolkit）
- **富文本/引用预览**：支持 Markdown 渲染（引用高亮、折叠上下文）

### 4.2 核心页面（建议）
- **检索页**：输入框 + 项目/文档范围过滤 + Top-K 列表 + 证据引用卡片
- **文档管理**：上传、版本、解析状态、失败重试、索引更新时间
- **需求点浏览**：按文档树（章节）+ 条款列表 + 关联功能标签
- **权限与审计**：用户/角色/项目授权；检索日志与访问日志

## 5. 后端选型

### 5.1 Web 框架与工程化
- **FastAPI**：接口规范（OpenAPI）、异步 IO 适合文档处理与检索
- **认证鉴权**：JWT + RBAC（或对接企业 SSO / OAuth2 / OIDC）
- **配置与密钥**：`.env` + Vault/云密钥（生产）
- **可观测性**：结构化日志 + Prometheus/Grafana（可选）+ trace（OpenTelemetry 可选）

### 5.2 核心服务拆分（建议）
- **文档同步服务**（新增）：飞书 API 集成、文档拉取、版本检测、增量更新、同步任务调度
- **Ingestion 服务**：解析→切分→抽取需求点→embedding→入库（异步任务）
- **Retrieval 服务**：query 改写→混合检索→重排→返回证据
- **Generation 服务**：基于证据生成总结（可选，可先只做"检索+引用"）

## 6. 数据库与存储选型

### 6.1 关系数据库（PostgreSQL）

**PostgreSQL 简介**
- PostgreSQL（简称 Postgres）是一个**开源的关系型数据库管理系统**（RDBMS）。
- 遵循 SQL 标准，支持 ACID 事务、外键、触发器、视图、存储过程等。
- 以**功能丰富、扩展性强、标准兼容性好**著称。

**为什么选 PostgreSQL（而非 MySQL）**

1. **向量扩展支持（关键原因）**
   - PostgreSQL 有 `pgvector` 扩展，可直接在数据库中存储和检索向量。
   - MySQL 目前没有成熟的向量扩展（虽然有实验性插件，但不够稳定）。
   - 对于 RAG 项目，这是选择 PostgreSQL 的**最重要原因**。

2. **全文检索能力更强**
   - PostgreSQL 内置全文检索（`tsvector`、`tsquery`、GIN 索引），支持中文分词（需配置）。
   - MySQL 的全文检索（FULLTEXT）功能相对较弱，对中文支持不够好。

3. **数据类型和功能更丰富**
   - 支持 JSON/JSONB、数组、范围类型、自定义类型等，适合复杂业务场景。
   - 支持递归查询（CTE）、窗口函数、物化视图等高级特性。

4. **标准兼容性更好**
   - 更严格遵循 SQL 标准，SQL 语法更规范。
   - 对复杂查询的支持更好。

**PostgreSQL vs MySQL 主要差异**

| 特性 | PostgreSQL | MySQL |
|------|-----------|-------|
| **向量支持** | ✅ pgvector 扩展成熟 | ❌ 无成熟向量扩展 |
| **全文检索** | ✅ 内置强大（tsvector/GIN） | ⚠️ FULLTEXT 功能有限 |
| **JSON 支持** | ✅ JSONB（二进制，性能好） | ✅ JSON（文本存储） |
| **事务隔离** | ✅ 支持所有隔离级别 | ⚠️ 默认隔离级别较弱 |
| **窗口函数** | ✅ 支持完善 | ✅ MySQL 8.0+ 支持 |
| **递归查询** | ✅ WITH RECURSIVE | ⚠️ MySQL 8.0+ 支持 |
| **存储过程** | ✅ PL/pgSQL（功能强） | ✅ 存储过程（语法不同） |
| **性能** | 复杂查询性能好 | 简单查询性能好 |
| **生态** | 企业级应用多 | Web 应用更常见 |

**语法差异示例**

```sql
-- 1. 字符串拼接
-- PostgreSQL
SELECT 'Hello' || ' ' || 'World';  -- 使用 ||
-- MySQL
SELECT CONCAT('Hello', ' ', 'World');  -- 使用 CONCAT()

-- 2. 分页
-- PostgreSQL
SELECT * FROM table LIMIT 10 OFFSET 20;
-- MySQL
SELECT * FROM table LIMIT 20, 10;  -- 注意参数顺序相反

-- 3. 日期函数
-- PostgreSQL
SELECT NOW(), CURRENT_DATE, EXTRACT(YEAR FROM NOW());
-- MySQL
SELECT NOW(), CURDATE(), YEAR(NOW());

-- 4. 布尔类型
-- PostgreSQL
CREATE TABLE test (is_active BOOLEAN);  -- 原生支持
-- MySQL
CREATE TABLE test (is_active TINYINT(1));  -- 用 TINYINT 模拟

-- 5. 数组类型
-- PostgreSQL
CREATE TABLE test (tags TEXT[]);  -- 原生支持数组
SELECT * FROM test WHERE 'tag1' = ANY(tags);
-- MySQL
-- 需要用 JSON 或单独的表来模拟数组
```

**总结**
- **对于这个 RAG 项目**：PostgreSQL + FAISS/Milvus（混合架构）是**推荐选择**，向量检索性能更好，便于未来扩展。
- **备选方案**：PostgreSQL + pgvector（一体化部署，适合小规模或追求简单部署的场景）。
- **如果不用向量扩展**：MySQL 也可以，但需要配合独立的向量数据库（FAISS/Milvus），架构更复杂。
- **学习成本**：PostgreSQL 与 MySQL 的 SQL 语法大部分相同，主要差异在高级特性和扩展能力。

**建议表设计（核心）**
- **`projects`**：项目/系统维度
- **`documents`**：文档主表
  - 字段：`doc_id`、`title`、`type`（飞书文档/本地文件）、`source_url`（飞书文档URL或本地文件路径）、`project_id`、`current_version_id`、`sync_enabled`（是否启用自动同步）、`last_sync_at`、`sync_status`（success/failed/pending）、`permission_domain`
- **`document_versions`**：版本表
  - 字段：`version_id`、`document_id`、`version_no`、`content_hash`（用于检测变化）、`created_at`、`created_by`、`status`（parsing/indexed/failed）、`file_path`（对象存储路径，飞书文档为同步后的Markdown/HTML）、`feishu_revision`（飞书文档版本号）
- **`doc_sections`**：章节树（父子结构、标题、层级路径、页码范围/锚点、飞书文档中的块ID）
- **`requirements`**：需求点（需求编号/条款号、标题、原文、所属章节、优先级/模块标签、来源版本）
- **`chunks`**：可检索最小单元（文本、位置、章节路径、关联 requirement_id，可为空、飞书块ID）
- **`sync_tasks`**：同步任务表（任务ID、文档ID、任务类型、状态、错误信息、执行时间）
- **`retrieval_logs`**：检索审计（user_id、query、filters、命中ids、耗时、token/费用估算）
- **`acl_*`**：RBAC（用户-角色-项目-文档范围授权）

**索引建议**
- `documents(project_id, type)`、`document_versions(document_id, created_at)` 等常用过滤字段建立 B-Tree。
- `requirements(requirement_no)`（便于直接编号查找）。
- 为全文检索列维护 `tsvector`（`chunks.tsv` 或 `requirements.tsv`），配合 GIN 索引。

### 6.2 向量检索能力

#### 方案 A：PostgreSQL + FAISS/Milvus（推荐：混合架构，高性能）
**架构设计**
- **PostgreSQL**：存储业务数据和元数据（`chunks` 表包含：`chunk_id`、`text`、`doc_id`、`section_path`、`page_no` 等，但不存储 `embedding`）。
- **FAISS/Milvus**：专门做向量检索，存储 `chunk_id` + `embedding`，通过 `chunk_id` 关联回 PostgreSQL 获取完整元数据。

**数据流**
1. 文档入库：生成 embedding → 写入 FAISS/Milvus（`chunk_id` + `vector`）→ 写入 PostgreSQL（`chunk_id` + 元数据）。
2. 检索流程：query embedding → FAISS/Milvus 向量检索（返回 Top-K `chunk_id` + 相似度）→ PostgreSQL 批量查询（`WHERE chunk_id IN (...)`）获取元数据 → 合并结果。

**FAISS vs Milvus 选择**
- **FAISS**：轻量、高性能、Python 接口简单，适合快速验证；需自行管理持久化、索引更新、元数据过滤（在应用层做）。
- **Milvus**：功能更全（元数据过滤、持久化、分布式、REST/gRPC API），适合生产环境；部署运维复杂度更高。

**实施建议**
- MVP 阶段：可先用 FAISS（快速验证，Python 库集成简单），或直接上 Milvus（一步到位，功能更全）。
- PostgreSQL `chunks` 表需建立 `chunk_id` 主键索引，确保批量查询性能。
- 考虑在 FAISS/Milvus 中存储少量常用元数据（如 `doc_id`、`project_id`）做预过滤，减少 PostgreSQL 查询量。
- 注意数据一致性：向量库与 PostgreSQL 的写入需保证原子性（或至少保证最终一致性）。
- **优势**：向量检索性能更好，适合未来扩展；业务数据与向量数据分离，便于独立优化。

#### 方案 B：pgvector（备选：一体化部署，简单）
**数据结构**
- `chunks.embedding vector(<dim>)` 或单独建 `chunk_embeddings` 表（便于多 embedding 版本共存）。
- 记录 `embedding_model`、`embedding_dim`、`embedding_version`，支持灰度升级与重建索引。

**索引类型（按规模选）**
- 小规模（< 10 万向量）：先用 `ivfflat` 或甚至无索引 + 过滤也能跑起来。
- 中等规模（10 万 ~ 百万）：`ivfflat`（简单稳定）或 `hnsw`（召回更好，写入成本更高）。

**优势**：业务数据与向量数据在同一数据库，部署运维最简单，元数据过滤与事务一致性天然支持。

**适用场景**：数据量较小（< 10 万向量）、希望最小化部署复杂度、单机部署。

### 6.3 全文检索（BM25）与混合检索
**为什么需要混合检索**
- 需求文档里大量是**编号/专有名词/接口字段/页面标题**，纯向量容易漏召回；BM25 对“字面匹配”强。

**实现建议**
- PostgreSQL 内置全文检索（`to_tsvector` + `websearch_to_tsquery`）做 BM25 近似（够用且部署最简）。
- 若未来需要更强的分词、同义词、聚合、权限过滤：再升级到 OpenSearch/Elasticsearch。

**混合策略（推荐）**
- 先各取 Top-N：向量 Top-50 + 全文 Top-50
- 合并去重后做 **重排**（rerank）取最终 Top-K（如 10）

### 6.4 对象存储

**为什么需要对象存储**
- 存放大文件（原始文档、解析产物）不适合直接存数据库（成本高、效率低）。
- 对象存储适合存储非结构化数据，通过 URL/Key 访问，支持版本控制、生命周期管理。

**存储内容**
- 原始文件：用户上传的 `.docx`、`.pdf` 等文档
- 解析中间产物：抽取文本、章节树 JSON、页码映射
- OCR 结果：扫描件识别后的文本
- 缩略图：文档预览图

**推荐方案：测试用 MinIO，生产用阿里云 OSS**

#### 方案 A：MinIO（测试/开发环境）
**特点**
- 开源、S3 兼容、可本地部署
- Docker 一键启动，适合开发测试
- 免费，无使用成本

**部署**
- Docker Compose 部署，与 PostgreSQL、Redis 一起启动
- 默认端口：9000（API）、9001（控制台）

**适用场景**
- 本地开发、测试环境
- 私有化部署（小规模）
- 快速验证功能

#### 方案 B：阿里云 OSS（生产环境）
**特点**
- 国内访问速度快，CDN 加速
- 高可用、自动备份
- 按使用量付费，成本可控
- 中文文档完善

**适用场景**
- 生产环境
- 需要高可用和自动备份
- 国内用户访问

**其他可选方案**
- **AWS S3**：使用 AWS 云服务时
- **腾讯云 COS**：使用腾讯云生态时
- **七牛云**：需要 CDN 加速时
- **本地文件系统**：极小规模、单机部署（不推荐生产环境）

#### 存储抽象层设计（推荐实现）

**设计思路**
- 定义统一的存储接口（StorageInterface），包含：上传、下载、删除、获取URL、列表等操作
- 实现 MinIO 和阿里云 OSS 的适配器，都实现同一接口
- 通过配置（环境变量）切换存储实现，业务代码无需修改

**接口抽象示例**
```python
# 统一接口定义
class StorageInterface:
    - upload_file(bucket, key, file_path) -> url
    - download_file(bucket, key, local_path)
    - delete_file(bucket, key)
    - get_file_url(bucket, key, expires) -> url
    - file_exists(bucket, key) -> bool
    - list_files(bucket, prefix) -> list
```

**实现方式**
- **MinIO 实现**：使用 `minio` Python 库，实现 S3 兼容接口
- **OSS 实现**：使用 `oss2` Python 库，实现阿里云 OSS 接口
- **工厂模式**：根据配置（`STORAGE_TYPE=minio|oss`）创建对应实例

**配置示例**
```env
# 开发环境 (.env.development)
STORAGE_TYPE=minio
MINIO_ENDPOINT=localhost:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin

# 生产环境 (.env.production)
STORAGE_TYPE=oss
OSS_ACCESS_KEY_ID=your_key_id
OSS_ACCESS_KEY_SECRET=your_key_secret
OSS_ENDPOINT=oss-cn-hangzhou.aliyuncs.com
OSS_BUCKET_NAME=rag-documents-prod
```

**优势**
- 代码统一：业务代码不关心底层存储实现
- 切换简单：改配置即可，无需改代码
- 易于测试：本地用 MinIO，生产用 OSS
- 扩展方便：新增存储类型只需实现接口

**文件命名规范**
- 统一路径格式：`project/<project_id>/doc/<doc_id>/ver/<ver_id>/<file_type>.<ext>`
- 例如：`project/123/doc/456/ver/v1.0/original.docx`
- 便于按项目/文档/版本组织，支持回收与审计

**注意事项**
- Bucket 命名：MinIO 和 OSS 的命名规则可能不同，建议统一规范
- URL 格式：预签名 URL 格式不同，但接口统一返回字符串
- 错误处理：不同存储的错误类型不同，需要统一封装异常
- 性能差异：OSS 可能有 CDN 加速，MinIO 需要自己配置

### 6.5 缓存与队列（Redis + Celery）
- **异步任务**：
  - 飞书文档同步（定时/手动触发）
  - 文档解析、OCR、embedding、重建索引、批量导入
- **重试与死信**：失败原因持久化到 `document_versions.error` 或 `sync_tasks.error`，支持手动重跑。
- **缓存**：热门 query 结果（短 TTL）、用户权限树（中 TTL）、飞书文档内容（中 TTL，减少 API 调用）。

## 7. 文档解析、切分与"需求点"抽取

### 7.1 文档接入方式

#### 方案 A：飞书云文档同步（主要来源）

**为什么需要数据库存储？**
- ✅ **必须存储**：需要索引文档内容（向量检索、全文检索）
- ✅ **版本管理**：追踪文档变化，支持历史版本查询
- ✅ **离线访问**：即使飞书文档不可访问，也能检索历史内容
- ✅ **性能优化**：本地索引比实时调用飞书 API 快得多
- ✅ **可追溯性**：需要记录文档的每个版本，支持"在某个时间点的文档内容"

**技术架构设计**

**1. 飞书开放平台集成**
- 使用飞书开放平台 API（需要企业应用授权）
- 主要 API：
  - `GET /open-apis/drive/v1/files/{file_token}/content`：获取文档内容
  - `GET /open-apis/drive/v1/files/{file_token}/meta`：获取文档元数据
  - `GET /open-apis/drive/v1/files/{file_token}/versions`：获取版本列表
- 认证方式：企业自建应用（App ID + App Secret）或用户授权（OAuth2）

**2. 文档同步服务设计**
```
┌─────────────┐      ┌──────────────┐      ┌─────────────┐
│  定时任务   │ ───> │ 飞书API调用  │ ───> │ 文档解析    │
│ (Celery)    │      │ (同步服务)   │      │ (解析器)    │
└─────────────┘      └──────────────┘      └─────────────┘
                            │                      │
                            ▼                      ▼
                    ┌──────────────┐      ┌─────────────┐
                    │ 版本检测     │ ───> │ 增量更新    │
                    │ (内容hash)   │      │ (向量库)    │
                    └──────────────┘      └─────────────┘
```

**3. 同步策略**
- **定时同步**：每天/每小时自动同步（可配置）
- **手动同步**：管理员手动触发同步
- **增量更新**：
  - 对比 `content_hash` 或 `feishu_revision` 判断是否变化
  - 变化则创建新版本，标记旧版本为历史
  - 只更新变化的 chunk（删除旧向量，插入新向量）

**4. 数据存储设计**
- **PostgreSQL**：存储文档元数据、版本信息、章节树、需求点
- **对象存储**：存储同步后的文档内容（Markdown/HTML格式，便于后续解析）
- **向量库**：存储 chunk embedding，通过 `chunk_id` 关联 PostgreSQL

**5. 引用定位设计**
- 每个 chunk 记录：`feishu_block_id`（飞书文档中的块ID）
- 检索结果返回：飞书文档 URL + 块ID，支持直接跳转到原文位置
- 格式：`https://xxx.feishu.cn/docx/xxx?block_id=xxx`

**6. 权限同步**
- 从飞书获取文档权限信息（谁可以访问）
- 同步到本地权限表，检索时做权限过滤

**实施建议**
- **MVP 阶段**：先实现手动同步，验证流程
- **生产环境**：实现定时同步 + 增量更新
- **错误处理**：同步失败记录错误，支持重试
- **监控告警**：同步任务失败、文档变化异常时告警

#### 方案 B：本地文件上传（备选）

**文档解析工具选型**
- **`.docx`**：`python-docx`（结构可靠，能读段落/标题样式/表格）
- **PDF（文本型）**：PyMuPDF（fitz）或 `pdfplumber`（提取文本、页码、坐标更友好）
- **PDF（扫描件/图片）**：PaddleOCR（中文效果较好）或 Tesseract（轻量）
- **统一抽取框架（可选）**：`unstructured` / `docling`（更强的版面理解，但引入复杂度更高）

**选型建议**：
- **飞书文档为主**：优先实现飞书 API 同步
- **本地文件为辅**：支持手动上传 Word/PDF 作为补充
- **MVP 阶段**：先实现飞书同步 + 基础解析，本地文件作为第二阶段

### 7.2 切分策略（决定检索上限的关键）
**原则**
- chunk 必须可被引用：必须带 `doc_id/ver_id` + `section_path` + `page_no/anchor`。
- chunk 不宜太短（信息不足）也不宜太长（向量稀释）。建议目标：**300–800 中文字**左右（按实际文档调参）。

**切分方法（推荐组合）**
- **按章节标题切分**：标题作为层级路径，chunk 继承 `section_path=["1 总则","1.2 范围",...]`。
- **按需求编号/条款号切分**：正则识别（如 `R\d+`、`REQ-\d+`、`1.2.3`、`（一）` 等）形成“需求点”。
- **滑窗补上下文**：对长条款可用 overlap（如 10–20%）保证召回稳定。

### 7.3 需求点抽取（Requirement Extraction）
**MVP 做法（强可控）**
- **规则优先**：用正则+标题样式识别“需求编号、条款、验收标准、例外情况”等段落。
- 输出 `requirements`：`requirement_no`、`title`（可从首句/加粗字段生成）、`text`、`section_id`、`page_no`。

**增强做法（准确率更高）**
- LLM 辅助：对每个章节让模型输出结构化 JSON（条款列表、编号、标题、约束、验收口径）。
- 做一致性校验：编号唯一、标题非空、长度阈值、与原文对齐。

## 8. Embedding / Rerank / 大模型选型

### 8.1 Embedding（向量化）
**要求**
- 中文强、支持中英文混合、语义检索稳定、成本可控。

**推荐：Qwen Embedding 模型**
- **Qwen2.5-7B-Instruct-Embedding**：7B 参数，中文优化，适合中文需求文档。
- **Qwen2.5-14B-Instruct-Embedding**：14B 参数，性能更强，适合大规模场景。
- **优势**：针对中文优化，与 Qwen LLM 生态一致，支持中英文混合。

**备选方案**
- **本地**：BGE 系列（如 BGE-M3 / bge-large-zh）适合中文需求文档。
- **云 API**：`text-embedding-3-large`（效果强，成本与合规需评估）。

**实践建议**
- embedding 输入要带上下文：`[项目名][文档类型][章节路径] + 段落正文`（提升可区分性）。
- 记录 embedding 版本，模型升级时支持“并行双写/按需重建”。

### 8.2 重排（Rerank）
**优先级**：当你发现"Top-K 命中不稳/引用不够准"，重排收益往往 > 盲目换更大 LLM。

**推荐方案对比**

| 模型 | 类型 | 优势 | 劣势 | 适用场景 |
|------|------|------|------|----------|
| **Jina Reranker** | 云API | 多语言支持、性能好、无需部署、API简单 | 依赖网络、需要API密钥 | 推荐：生产环境首选 |
| **Cohere rerank** | 云API | 性能好、无需部署 | 成本较高、依赖网络 | 备选：快速验证 |
| **bge-reranker** | 本地部署 | 免费、延迟低、可控性强 | 需要本地资源 | 备选：本地部署场景 |
| **Cross-Encoder** | 通用方案 | 灵活、可自定义 | 需要训练/调优 | 高级场景 |
| **LLM rerank** | LLM评分 | 可理解语义、可解释 | 成本高、延迟高 | 小流量或离线评估 |

**推荐选择：Jina Reranker**
- **理由**：多语言支持（包括中文）、性能优异、API 简单易用、无需本地部署资源。
- **部署**：云 API 服务，通过 HTTP API 调用，无需本地模型部署。
- **性能**：在中文重排任务上表现优异，支持多语言混合场景。
- **成本**：按调用量计费，适合生产环境使用。
- **特性**：
  - 支持多语言（中文、英文等）
  - 高效的推理速度
  - 适用于 RAG 场景
  - 提供 RESTful API，集成简单

**备选：Cohere rerank**
- **适用**：快速验证、小规模场景、不想维护本地服务。
- **注意**：需要评估 API 成本和网络延迟。

**备选：bge-reranker**
- **适用**：需要本地部署、对数据隐私要求高、不想依赖外部 API。
- **注意**：需要本地 GPU/CPU 资源，部署和维护成本。

### 8.3 LLM（生成与推理）
**在本项目中 LLM 的合理定位**
- **不是"编答案"**，而是做：query 改写、证据解释、引用整理、结构化输出（JSON）。
- 强约束：答案必须来自检索证据；无证据则明确"不确定/未检索到"。

**云泽云 API Qwen 系列模型对比**

| 模型 | 功能特点 | 价格（元/千tokens） | 性能表现 | 适用场景 |
|------|---------|-------------------|---------|----------|
| **Qwen-Max** | 旗舰模型，性能最强 | 输入：0.04<br>输出：约0.12 | 综合能力最强，中文理解优秀 | 推荐：对质量要求高的生产环境 |
| **Qwen-Plus** | 平衡性能与成本 | 输入：约0.008<br>输出：约0.024 | 性能良好，性价比高 | 推荐：大多数生产场景 |
| **Qwen-Turbo** | 快速响应 | 输入：约0.002<br>输出：约0.006 | 速度快，成本低 | 适合：高并发、对延迟敏感 |
| **Qwen-Long** | 超长上下文（1000万tokens） | 输入：0.0005<br>输出：约0.0015 | 长文本处理强 | 适合：处理超长文档、成本敏感 |

**详细对比分析**

**1. 功能对比**
- **Qwen-Max**：✅ 最强理解能力、✅ 复杂推理、✅ 高质量生成、✅ 中文优化
- **Qwen-Plus**：✅ 良好理解能力、✅ 基础推理、✅ 稳定生成、✅ 中文优化
- **Qwen-Turbo**：✅ 快速响应、✅ 基础理解、⚠️ 复杂任务较弱、✅ 中文优化
- **Qwen-Long**：✅ 超长上下文、✅ 长文档理解、⚠️ 单次推理能力中等、✅ 中文优化

**2. 价格对比（以处理1000次查询，每次输入2k tokens，输出1k tokens为例）**
- **Qwen-Max**：约 80 元（2k×0.04 + 1k×0.12）×1000
- **Qwen-Plus**：约 16 元（2k×0.008 + 1k×0.024）×1000
- **Qwen-Turbo**：约 4 元（2k×0.002 + 1k×0.006）×1000
- **Qwen-Long**：约 1 元（2k×0.0005 + 1k×0.0015）×1000

**3. 性能对比**
- **Qwen-Max**：⭐⭐⭐⭐⭐ 综合能力最强，适合复杂任务
- **Qwen-Plus**：⭐⭐⭐⭐ 性能良好，性价比最高
- **Qwen-Turbo**：⭐⭐⭐ 速度快，适合简单任务
- **Qwen-Long**：⭐⭐⭐⭐ 长文本处理强，单次推理中等

**推荐选择：Qwen-Plus（推荐）或 Qwen-Max（高质量场景）**

**选择建议**
- **推荐：Qwen-Plus**
  - **理由**：性能与成本平衡，适合大多数 RAG 场景（query 改写、引用整理、结构化输出）。
  - **适用**：生产环境、中等质量要求、成本可控。

- **备选：Qwen-Max**
  - **理由**：性能最强，适合对质量要求极高的场景。
  - **适用**：高质量要求、复杂推理、预算充足。

- **备选：Qwen-Turbo**
  - **理由**：成本极低，响应快。
  - **适用**：高并发、简单任务、成本敏感。

- **特殊场景：Qwen-Long**
  - **理由**：超长上下文，价格极低。
  - **适用**：需要处理超长文档、一次性处理大量上下文。

**实施建议**
- **起步阶段**：先用 Qwen-Plus 验证效果，根据实际表现调整。
- **生产环境**：根据质量要求和成本预算选择 Qwen-Plus 或 Qwen-Max。
- **成本优化**：简单任务用 Qwen-Turbo，复杂任务用 Qwen-Plus/Max。
- **统一网关**：建议封装统一 LLM 调用接口，便于切换模型和限流、日志、脱敏。

## 9. RAG 框架与工程实现

### 9.1 RAG 框架选型
- **LlamaIndex（推荐）**：索引与节点模型清晰，元数据与引用能力强，适合“文档→章节→需求点”的结构化场景。
- **LangChain（备选）**：生态广、组件多，适合复杂 Agent/工具调用，但需要更多工程约束避免链路失控。
- **Haystack（备选）**：更偏检索系统工程化，适合后期做大规模检索服务。

### 9.2 检索链路（建议实现顺序）
1) **只做检索**：返回 Top-K 需求点 + 引用（不生成长答案）  
2) **加入重排**：稳定 Top-K  
3) **加入生成**：输出“结论 + 引用清单 + 解释为什么命中”

### 9.3 引用与可追溯（必须做对）
- 每个 chunk 保存：`doc_id`、`ver_id`、`section_path`、`page_no/anchor`、`char_start/end`（能做到更好）。
- **飞书文档**：额外保存 `feishu_block_id`，支持直接跳转到飞书文档原文位置。
- 前端提供：
  - 原文预览（本地缓存内容）
  - 上下文展开（前后 N 段）
  - **跳转到飞书文档**（通过 URL + block_id）
  - 下载原文件（受权限控制，飞书文档可导出为 PDF）

## 10. 权限、合规与安全
- **RBAC**：用户→角色→项目→文档/版本权限；检索时强制过滤可见范围。
- **数据脱敏**：入库前/展示前支持敏感字段掩码（手机号、证件号等）。
- **审计**：记录“谁在何时检索了什么、命中了哪些文档片段、是否导出/下载”。
- **模型侧安全**：提示词注入防护（只允许从检索证据回答）；输出前做引用校验（无引用则拒答/降级）。

## 11. 部署与环境（推荐从最小可用开始）

### 11.1 本地/开发（Windows 友好）
- 推荐使用 **Docker Compose** 起 PostgreSQL、Redis、MinIO（对象存储）。
- 向量检索：FAISS（Python 库，无需额外服务）或 Milvus（Docker 部署）。
- 对象存储：MinIO（Docker 部署，S3 兼容，适合开发测试）。
- 后端 FastAPI 本地跑；前端 Next.js 本地跑。

### 11.2 生产（分阶段）
- **对象存储**：阿里云 OSS（推荐，高可用、自动备份）或其他云存储服务。
- **单机/小团队**：Docker Compose + 反向代理（Nginx/Caddy）+ 阿里云 OSS。
- **多团队/高可用**：Kubernetes（PostgreSQL 主从或云托管，向量库可再评估独立化）+ 阿里云 OSS。
- **存储切换**：通过环境变量配置（`STORAGE_TYPE=oss`），代码无需修改。

## 12. 评估体系（让检索“可度量、可迭代”）
- **离线评估集**：从真实问题构建（query → 标注正确需求点/文档片段）。
- **指标**：Recall@K、MRR、nDCG；以及“引用是否正确/是否可定位”。
- **A/B**：切分策略、embedding 模型、是否重排、不同过滤策略。

## 13. 里程碑（建议）
- **M1（1–2 周）**：
  - 飞书 API 集成（获取文档内容）
  - 文档同步服务（手动同步）
  - 解析（Markdown/HTML → 文本/章节树）
  - 切分 → 向量化 → 检索 Top-K + 引用预览
- **M2（2–4 周）**：
  - 定时同步任务（Celery）
  - 版本检测与增量更新
  - 需求点抽取（规则为主）
  - 混合检索（向量+全文）
  - 基础权限/审计
- **M3（4–6 周）**：
  - 重排、query 改写、生成总结（严格引用）
  - 飞书文档跳转（URL + block_id）
  - 评估集与指标
- **M4（持续）**：
  - 本地文件上传（Word/PDF，备选）
  - OCR、实体/标签体系、跨项目检索
  - 独立向量库/搜索引擎升级

## 14. 关键取舍（明确边界，避免返工）
- **先做“检索+引用”再做“生成”**：对你这个“追溯需求点”的场景，检索质量与可追溯性是第一优先。
- **向量检索架构**：推荐 PostgreSQL + FAISS/Milvus（混合架构，性能好、易扩展）；备选 pgvector（一体化部署，适合小规模）。
- **抽取需求点优先规则**：需求文档格式往往稳定，规则可控、可解释；LLM 作为增强而不是替代。

