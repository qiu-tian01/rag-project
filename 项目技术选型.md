# 项目技术选型（RAG：按“需求文档 → 需求点”追溯项目功能）

## 1. 背景与目标

### 1.1 业务问题
- **目标**：输入“项目功能/模块/用户故事/关键字”，快速定位**历史需求文档**中涉及该功能的**具体需求点**，并给出**可追溯证据**（文档名、版本、章节/段落、页码/标题、引用原文片段、相似度/置信度）。
- **典型输入**：功能名称、页面名、接口名、业务规则、异常场景、验收口径等。
- **典型输出**：
  - Top-K 需求点（含：文档ID/版本/发布日期/需求编号/标题/章节路径/原文摘录/引用定位/评分）
  - 可展开查看上下文（前后若干段）
  - “为什么命中”（关键词高亮、相似度、重写后的检索query）

### 1.2 核心能力清单（MVP → 可扩展）
- **文档接入**：Word（`.docx`）、PDF、Markdown、HTML（可选：图片/扫描件 OCR）。
- **结构化切分**：按“章节标题→需求编号→条款”切分，保留层级路径。
- **可追溯引用**：返回答案必须附带引用（quote + 位置）。
- **混合检索**：向量检索 + 关键词/全文检索 + 元数据过滤。
- **需求点识别**：从文档自动抽取“需求点/条款”并作为一等实体管理。
- **权限与审计**：按项目/文档范围授权；记录检索与访问审计。

## 2. 总体架构与数据流

### 2.1 架构概览（推荐）
- **前端**：Web 应用（查询、结果列表、引用预览、文档管理、权限管理）
- **后端 API**：RAG 服务（检索、重排、生成、引用拼装），文档入库与任务编排
- **数据存储**：
  - 业务关系数据（项目/文档/版本/需求点/权限/审计）
  - 向量索引（chunk/需求点向量）
  - 对象存储（原始文件、解析后的中间产物）
  - 缓存与队列（任务、会话、速率限制）
- **LLM/Embedding**：用于 query 改写、召回增强、重排（可选）、答案生成与引用整理

### 2.2 数据流（离线入库）
1) 上传文档 → 2) 解析（提取文本/标题层级/页码/表格）  
3) 识别“需求点”（规则 + LLM/NER，可选）  
4) 生成 chunk（保留层级元数据）→ 5) Embedding → 6) 写入向量库 + 写入关系库（索引元数据）  
7) 可选：生成摘要、关键词、实体标签（功能、模块、接口、角色、系统名）

### 2.3 数据流（在线检索问答）
1) 用户 query → 2) query 改写/扩展（可选）  
3) 混合检索（向量 + BM25）+ 元数据过滤（项目/时间/版本/文档类型）  
4) 重排（Cross-Encoder 或 LLM 评分，可选）  
5) 生成答案（严格基于引用）+ 输出引用清单 + 可回溯定位信息

## 3. 技术选型总览（推荐组合 + 备选）

### 3.1 推荐默认方案（性价比/可控/企业落地友好）
- **前端**：Next.js（React + TypeScript）+ Tailwind CSS + Ant Design（或 shadcn/ui）
- **后端**：Python FastAPI（异步、高吞吐、生态成熟）
- **关系数据库**：PostgreSQL（承载业务数据与全文检索/结构化过滤）
- **向量能力**：`pgvector`（与 PostgreSQL 合一，部署简单，MVP 首选）
- **对象存储**：MinIO（S3 兼容，存原文件与解析产物）
- **缓存/队列**：Redis + Celery（或 RQ/Arq）用于异步入库、重试、限流
- **RAG 框架**：LlamaIndex（文档索引、节点/元数据、检索链路清晰）  
  - 备选：LangChain（生态更广）、Haystack（检索工程化强）
- **重排模型**：bge-reranker（本地部署可选）或 LLM rerank（成本更高）
- **Embedding**：BGE-M3 / bge-large-zh / text-embedding-3-large（视中英文与成本）
- **大模型（LLM）**：
  - **本地/私有化**：Qwen2.5 / DeepSeek / Llama（按算力选 7B/14B/32B）
  - **云API**：OpenAI / Azure OpenAI / 国内主流云厂商（便于起步）

### 3.2 扩展方案（更大规模/更强检索）
- **向量数据库独立化**：Milvus / Qdrant / Weaviate（适合百万级以上向量与更复杂索引）
- **全文检索**：OpenSearch/Elasticsearch（BM25、聚合与权限过滤更强）
- **服务编排**：Kubernetes + Helm（多环境、弹性扩缩）

## 4. 前端选型

### 4.1 技术栈
- **框架**：Next.js（App Router）+ TypeScript
- **UI**：Tailwind CSS + Ant Design（表格/筛选/权限管理效率高）
- **状态与请求**：TanStack Query + Zustand（或 Redux Toolkit）
- **富文本/引用预览**：支持 Markdown 渲染（引用高亮、折叠上下文）

### 4.2 核心页面（建议）
- **检索页**：输入框 + 项目/文档范围过滤 + Top-K 列表 + 证据引用卡片
- **文档管理**：上传、版本、解析状态、失败重试、索引更新时间
- **需求点浏览**：按文档树（章节）+ 条款列表 + 关联功能标签
- **权限与审计**：用户/角色/项目授权；检索日志与访问日志

## 5. 后端选型

### 5.1 Web 框架与工程化
- **FastAPI**：接口规范（OpenAPI）、异步 IO 适合文档处理与检索
- **认证鉴权**：JWT + RBAC（或对接企业 SSO / OAuth2 / OIDC）
- **配置与密钥**：`.env` + Vault/云密钥（生产）
- **可观测性**：结构化日志 + Prometheus/Grafana（可选）+ trace（OpenTelemetry 可选）

### 5.2 核心服务拆分（建议）
- **Ingestion 服务**：上传→解析→切分→抽取需求点→embedding→入库（异步任务）
- **Retrieval 服务**：query 改写→混合检索→重排→返回证据
- **Generation 服务**：基于证据生成总结（可选，可先只做“检索+引用”）

## 6. 数据库与存储选型

### 6.1 关系数据库（PostgreSQL）

**为什么选 PostgreSQL**
- **业务数据**（权限、项目、文档版本、需求点、审计）天然关系型。
- **结构化过滤**（按项目/系统/版本/时间/文档类型/状态）与事务一致性更省心。
- 可结合 `pgvector` 把向量能力收敛到一个数据库，MVP 部署/运维成本最低。

**建议表设计（核心）**
- **`projects`**：项目/系统维度
- **`documents`**：文档主表（标题、类型、项目归属、当前版本指针、权限域）
- **`document_versions`**：版本表（版本号、发布日期、文件hash、上传人、状态：parsing/indexed/failed）
- **`doc_sections`**：章节树（父子结构、标题、层级路径、页码范围/锚点）
- **`requirements`**：需求点（需求编号/条款号、标题、原文、所属章节、优先级/模块标签、来源版本）
- **`chunks`**：可检索最小单元（文本、位置、章节路径、关联 requirement_id，可为空）
- **`retrieval_logs`**：检索审计（user_id、query、filters、命中ids、耗时、token/费用估算）
- **`acl_*`**：RBAC（用户-角色-项目-文档范围授权）

**索引建议**
- `documents(project_id, type)`、`document_versions(document_id, created_at)` 等常用过滤字段建立 B-Tree。
- `requirements(requirement_no)`（便于直接编号查找）。
- 为全文检索列维护 `tsvector`（`chunks.tsv` 或 `requirements.tsv`），配合 GIN 索引。

### 6.2 向量检索能力（pgvector，MVP 首选）
**数据结构**
- `chunks.embedding vector(<dim>)` 或单独建 `chunk_embeddings` 表（便于多 embedding 版本共存）。
- 记录 `embedding_model`、`embedding_dim`、`embedding_version`，支持灰度升级与重建索引。

**索引类型（按规模选）**
- 小规模（< 10 万向量）：先用 `ivfflat` 或甚至无索引 + 过滤也能跑起来。
- 中等规模（10 万 ~ 百万）：`ivfflat`（简单稳定）或 `hnsw`（召回更好，写入成本更高）。

### 6.3 全文检索（BM25）与混合检索
**为什么需要混合检索**
- 需求文档里大量是**编号/专有名词/接口字段/页面标题**，纯向量容易漏召回；BM25 对“字面匹配”强。

**实现建议**
- PostgreSQL 内置全文检索（`to_tsvector` + `websearch_to_tsquery`）做 BM25 近似（够用且部署最简）。
- 若未来需要更强的分词、同义词、聚合、权限过滤：再升级到 OpenSearch/Elasticsearch。

**混合策略（推荐）**
- 先各取 Top-N：向量 Top-50 + 全文 Top-50
- 合并去重后做 **重排**（rerank）取最终 Top-K（如 10）

### 6.4 对象存储（MinIO / S3）
- 存放：原文件、解析中间产物（抽取文本/章节树 JSON/页码映射）、OCR 结果、缩略图。
- 命名：`project/<project_id>/doc/<doc_id>/ver/<ver_id>/...`，便于回收与审计。

### 6.5 缓存与队列（Redis + Celery）
- **异步任务**：解析、OCR、embedding、重建索引、批量导入。
- **重试与死信**：失败原因持久化到 `document_versions.error`，支持手动重跑。
- **缓存**：热门 query 结果（短 TTL）、用户权限树（中 TTL）。

## 7. 文档解析、切分与“需求点”抽取

### 7.1 文档解析工具选型
- **`.docx`**：`python-docx`（结构可靠，能读段落/标题样式/表格）
- **PDF（文本型）**：PyMuPDF（fitz）或 `pdfplumber`（提取文本、页码、坐标更友好）
- **PDF（扫描件/图片）**：PaddleOCR（中文效果较好）或 Tesseract（轻量）
- **统一抽取框架（可选）**：`unstructured` / `docling`（更强的版面理解，但引入复杂度更高）

选型建议：**MVP 先分别实现 docx + pdf 文本型**，把“结构化切分 + 可引用定位”打通；OCR 作为第二阶段补齐。

### 7.2 切分策略（决定检索上限的关键）
**原则**
- chunk 必须可被引用：必须带 `doc_id/ver_id` + `section_path` + `page_no/anchor`。
- chunk 不宜太短（信息不足）也不宜太长（向量稀释）。建议目标：**300–800 中文字**左右（按实际文档调参）。

**切分方法（推荐组合）**
- **按章节标题切分**：标题作为层级路径，chunk 继承 `section_path=["1 总则","1.2 范围",...]`。
- **按需求编号/条款号切分**：正则识别（如 `R\d+`、`REQ-\d+`、`1.2.3`、`（一）` 等）形成“需求点”。
- **滑窗补上下文**：对长条款可用 overlap（如 10–20%）保证召回稳定。

### 7.3 需求点抽取（Requirement Extraction）
**MVP 做法（强可控）**
- **规则优先**：用正则+标题样式识别“需求编号、条款、验收标准、例外情况”等段落。
- 输出 `requirements`：`requirement_no`、`title`（可从首句/加粗字段生成）、`text`、`section_id`、`page_no`。

**增强做法（准确率更高）**
- LLM 辅助：对每个章节让模型输出结构化 JSON（条款列表、编号、标题、约束、验收口径）。
- 做一致性校验：编号唯一、标题非空、长度阈值、与原文对齐。

## 8. Embedding / Rerank / 大模型选型

### 8.1 Embedding（向量化）
**要求**
- 中文强、支持中英文混合、语义检索稳定、成本可控。

**推荐**
- **本地**：BGE 系列（如 BGE-M3 / bge-large-zh）适合中文需求文档。
- **云 API**：`text-embedding-3-large`（效果强，成本与合规需评估）。

**实践建议**
- embedding 输入要带上下文：`[项目名][文档类型][章节路径] + 段落正文`（提升可区分性）。
- 记录 embedding 版本，模型升级时支持“并行双写/按需重建”。

### 8.2 重排（Rerank）
- **优先级**：当你发现“Top-K 命中不稳/引用不够准”，重排收益往往 > 盲目换更大 LLM。
- **本地**：bge-reranker（性价比高，延迟可控）
- **LLM 重排**：按“与 query 的匹配度/是否包含验收口径/是否为需求点”打分（成本较高，适合小流量或离线评估）

### 8.3 LLM（生成与推理）
**在本项目中 LLM 的合理定位**
- **不是“编答案”**，而是做：query 改写、证据解释、引用整理、结构化输出（JSON）。
- 强约束：答案必须来自检索证据；无证据则明确“不确定/未检索到”。

**推荐路线**
- 起步：云 API（接入快）+ 严格引用模板
- 落地：私有化 Qwen2.5/DeepSeek（按合规与成本）+ 统一网关（限流、日志、脱敏）

## 9. RAG 框架与工程实现

### 9.1 RAG 框架选型
- **LlamaIndex（推荐）**：索引与节点模型清晰，元数据与引用能力强，适合“文档→章节→需求点”的结构化场景。
- **LangChain（备选）**：生态广、组件多，适合复杂 Agent/工具调用，但需要更多工程约束避免链路失控。
- **Haystack（备选）**：更偏检索系统工程化，适合后期做大规模检索服务。

### 9.2 检索链路（建议实现顺序）
1) **只做检索**：返回 Top-K 需求点 + 引用（不生成长答案）  
2) **加入重排**：稳定 Top-K  
3) **加入生成**：输出“结论 + 引用清单 + 解释为什么命中”

### 9.3 引用与可追溯（必须做对）
- 每个 chunk 保存：`doc_id`、`ver_id`、`section_path`、`page_no/anchor`、`char_start/end`（能做到更好）。
- 前端提供：原文预览、上下文展开（前后 N 段）、下载原文件（受权限控制）。

## 10. 权限、合规与安全
- **RBAC**：用户→角色→项目→文档/版本权限；检索时强制过滤可见范围。
- **数据脱敏**：入库前/展示前支持敏感字段掩码（手机号、证件号等）。
- **审计**：记录“谁在何时检索了什么、命中了哪些文档片段、是否导出/下载”。
- **模型侧安全**：提示词注入防护（只允许从检索证据回答）；输出前做引用校验（无引用则拒答/降级）。

## 11. 部署与环境（推荐从最小可用开始）

### 11.1 本地/开发（Windows 友好）
- 推荐使用 **Docker Compose** 起 PostgreSQL（含 pgvector）、Redis、MinIO。
- 后端 FastAPI 本地跑；前端 Next.js 本地跑。

### 11.2 生产（分阶段）
- 单机/小团队：Docker Compose + 反向代理（Nginx/Caddy）
- 多团队/高可用：Kubernetes（PostgreSQL 主从或云托管，向量库可再评估独立化）

## 12. 评估体系（让检索“可度量、可迭代”）
- **离线评估集**：从真实问题构建（query → 标注正确需求点/文档片段）。
- **指标**：Recall@K、MRR、nDCG；以及“引用是否正确/是否可定位”。
- **A/B**：切分策略、embedding 模型、是否重排、不同过滤策略。

## 13. 里程碑（建议）
- **M1（1–2 周）**：文档上传/解析（docx+pdf文本）→ 切分 → 向量化 → 检索 Top-K + 引用预览
- **M2（2–4 周）**：需求点抽取（规则为主）→ 混合检索（向量+全文）→ 基础权限/审计
- **M3（4–6 周）**：重排、query 改写、生成总结（严格引用）→ 评估集与指标
- **M4（持续）**：OCR、实体/标签体系、跨项目检索、独立向量库/搜索引擎升级

## 14. 关键取舍（明确边界，避免返工）
- **先做“检索+引用”再做“生成”**：对你这个“追溯需求点”的场景，检索质量与可追溯性是第一优先。
- **MVP 用 pgvector**：部署简单、迭代快；向量规模上来后再考虑 Milvus/Qdrant。
- **抽取需求点优先规则**：需求文档格式往往稳定，规则可控、可解释；LLM 作为增强而不是替代。

